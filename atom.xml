<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://DX990307.github.io</id>
    <title>Daoxuan Xu&apos;s Homepage</title>
    <updated>2023-10-13T00:25:04.173Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://DX990307.github.io"/>
    <link rel="self" href="https://DX990307.github.io/atom.xml"/>
    <subtitle>纵使困顿难行，亦当砥砺奋进</subtitle>
    <logo>https://DX990307.github.io/images/avatar.png</logo>
    <icon>https://DX990307.github.io/favicon.ico</icon>
    <rights>All rights reserved 2023, Daoxuan Xu&apos;s Homepage</rights>
    <entry>
        <title type="html"><![CDATA[读书笔记--计算机组成与设计 硬件软件接口 risc-v 第二章]]></title>
        <id>https://DX990307.github.io/post/du-shu-bi-ji-ji-suan-ji-zu-cheng-yu-she-ji-ying-jian-ruan-jian-jie-kou-risc-v-di-er-zhang/</id>
        <link href="https://DX990307.github.io/post/du-shu-bi-ji-ji-suan-ji-zu-cheng-yu-she-ji-ying-jian-ruan-jian-jie-kou-risc-v-di-er-zhang/">
        </link>
        <updated>2023-10-12T10:33:46.000Z</updated>
        <content type="html"><![CDATA[<h2 id="211-指令与并行性同步">2.11 指令与并行性：同步</h2>
<p>在并行工作时，任务之间通常需要协作。在协作中，一个任务A所需要的值可能为另外一个任务B所产生。为了避免任务A在执行时任务B的结果还没有到所产生的__数据竞争__，任务之间需要进行同步。<br>
<strong>数据竞争(data race)</strong> : 如果来自两个不同的县城的访存请求访问统一位置，至少有一个时写， 且连续出现，那么这两次存储访问形成了数据竞争。<br>
同步机制是由lock和unlock产生互斥所实现的，lock和unlock可以创建只有单个处理器可以操作的区域，称之为互斥区。在多处理器中，实现同步所需的时一组硬件原语，在内存单元读取和卸乳之间不插入任何其他操作的方式实现同步，这种方式称之为原子（Atom）。<br>
<strong>E.g. 原子交换</strong><br>
原子交换是构建同步机制的典型操作，将寄存器和存储器中的值进行交换。<br>
我们规定<br>
* 0 表示变量锁可用<br>
* 1 表示变量锁被占用<br>
那么<br>
场景1<br>
* 处理器A通过设置寄存器相对应地址A的值来设置变量锁<br>
* 处理器B在访问这个地址A之前先执行一段程序来检查寄存器中的值来判断是否被占用<br>
* 当未被占用时，程序返回0，处理器B可以正常访问这一段地址所存储的值<br>
* 当被占用时，程序返回1，说明这一段地址所存储的值正在被A占用，当A处理完后，将变量锁置0，处理器B可以正常访问。<br>
场景2<br>
* 当处理器A和B同时想要访问一段地址时，只有一个处理器可以得到这段地址中内容的访问权，另外一个需要等待。<br>
<strong>指令对</strong><br>
指令对实现原子操作的方式是在指令对执行时，任何其他指令的执行都在其前或其后（换句话说在执行这个指令对时，没有其他的操作对其进行干扰）。一般在指令对的第二条指令中会返回一个值来表示这个指令对是否时原子执行的。<br>
RISC-V中由load-reserved(<code>lr.d</code>)和store-conditional(<code>sc.d</code>)的特殊指令实现，在<code>lr.d</code>所指定的地址在<code>sc.d</code>执行前是不会被更改的。</p>
<pre><code>again:   lr.d   x10,    (x20) 
           sc.d   x11,   x23,   (x20)
           bne  x11,    x0,     again
           addi x23,    x10,    0
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[MPI Send/Recv]]></title>
        <id>https://DX990307.github.io/post/mpi-sendrecv/</id>
        <link href="https://DX990307.github.io/post/mpi-sendrecv/">
        </link>
        <updated>2023-03-06T13:43:46.000Z</updated>
        <content type="html"><![CDATA[<h1 id="mid-term-code-review">Mid-term Code review</h1>
<h2 id="module-2a">Module 2a</h2>
<h3 id="hello-worldmpi">Hello world(MPI)</h3>
<p>assuse the total number of the rank is 8.</p>
<pre><code class="language-c">#include &quot;mpi.h&quot;
#include &lt;stdio.h&gt;
void main(int argc, char *argv[])
{
    int RankID, NumOfRanks;
    MPI_Init(&amp;argc, &amp;argv);
    MPI_Comm_Rank(MPI_Comm_WORLD, &amp;RankID);
    MPI_Comm_Size(MPI_Comm_WORLD, &amp;NumOfRanks);
    printf(&quot;I am rank %d, total %d&quot;, RankID, NumOfRanks);
    MPI_Finalize();
    return 0;
}
</code></pre>
<p>The out of the code graph is</p>
<pre><code>I am rank 0, total 8
I am rank 3, total 8
...
</code></pre>
<h3 id="mpi_sendmpi_recv-example">MPI_send/MPI_Recv Example</h3>
<pre><code class="language-c">#include &quot;mpi.h&quot;
#include &lt;stdio.h&gt;
#include &lt;string.h&gt;

#define MASTER = 0; // define the master rank is rank 0;
int main(int argc, char *argv[])
{
    int RankID, NumOfRanks; // define rankid for the rank itself, and the total number of the ranks.
    int source, dest; // define sender(source) and receiving rank(daest)
    int tag = 0; //tag of message buffer.
    char buffer[100];
    MPI_Status status;

    MPI_Init(&amp;argc, &amp;argv);
    MPI_Comm_Rank(MPI_Comm_WORLD, &amp;RankID);
    MPI_Comm_Size(MPI_Comm_WORLD, &amp;NumOfRanks);
    if(RankID != 0)
    {
        sprintf(buffer, &quot;Greetings from %d&quot;, RankID); // store &quot;Gretting from RankID&quot; into buffer;
        dest = MASTER;
        counts = strlen(buffer) + 1; // total counts of the char in buffer
        MPI_Send(buffer, counts, MPI_CHAR, dest, tag, MPI_COMM_WORLD);
    }
    else
    {
        for(source = 1; source &lt; NumOfRanks; source++)
        {
            MPI_Recv(buffer, 100, srouce, tag, MPI_COMM_WORLD, &amp;status);
            printf(&quot;%s\n&quot;, buffer);
        }
    }
    return 0;
}
</code></pre>
<p>The output should be</p>
<pre><code>Greetings from 1
Greetings from 2
Greetings from 3
Greetings from 4
Greetings from 5
Greetings from 6
Greetings from 7
</code></pre>
<p>revisit the code of <code>MPI_Send</code> and <code>MPI_Recv</code><br>
<strong>MPI_Send</strong></p>
<pre><code class="language-c">MPI_Send(void *buffer, 
         int count, 
         MPI_DataType, MPI_CHAR
         int dest
         int tag
         MPI_COMM_WORLD);
</code></pre>
<p>buffer: the buffer that will be sent;</p>
<p>count: the total number of counts that will be sent;</p>
<p>MPI_DataType : the type that will be sent. E.g. MPI_INT, MPI_DOUBLE;</p>
<p>dest: The destination of the Send function;</p>
<p>tag: message tag, that is used to be distinguish messages that are sent by the same sender simultaneously.<br>
When A sends a message to B, A will package the message and send the message to the rank that processes B. When B receive the message successfully, it will send back a message to tell A that &quot;I receive the message from you successfully&quot;. After that, A will execute other operations. Sometimes, A will send several messages to B simultaneously. B needs to use parameter &quot;tag&quot; to distinguish messages sent by A.</p>
<p>MPI_COMM_WORLD: the zone that processor located in.</p>
<p><strong>MPI_Recv</strong></p>
<pre><code class="language-c">MPI_Recv(
    void *buffer,
    int count,
    MPI_DataType, MPI_CHAR,
    int source,
    int tag,
    MPI_COMM_WORLD,
    &amp;status
);
</code></pre>
<p>&amp;status <sup>[1]</sup>: MPI_status is a kind of data structure, which includes</p>
<ol>
<li>the rank of the sender, the rank of the sender is stored in the <code>MPO_SOURCE</code> element of the structure. That is if we declare an <code>MPI_Status status</code> variable, the rank can be accessed with <code>status.MPI_SOURCE</code>.</li>
<li>The tag of the message. The tag of the message can be accessed by the <code>MPI_TAG</code> element of the structure.</li>
<li>The length of the message. The length of the message does not have a predefined element in the status structure. Instead, we have to find out the length of the message with <code>MPI_Get_count</code>.</li>
</ol>
<h3 id="another-example-of-mpi_sendmpi_recv">Another Example of MPI_Send/MPI_Recv</h3>
<p>matrix multiplication</p>
<p>The main code of the matrix multiplication</p>
<pre><code class="language-c">for(i = 0; i&lt;NRA; i++)
    for(j = 0; j&lt;NCB; j++)
    {
        c[i][j] = 0;
        for (k = 0; k &lt; NCA; k++)
            c[i][j] = c[i][j] + a[i][k] * b[k][j];
    }
</code></pre>
<p>MPI code (main code) Use a <strong>master/worker style</strong> architecture</p>
<p>Master rank perform coodrination:</p>
<ul>
<li>Distributes rows of Martix A</li>
<li>Send all of Martix B to each worker ranks.</li>
</ul>
<p>Workers</p>
<ul>
<li>On its own data to create a partical C martix</li>
<li>Sends partical result back to master rank</li>
</ul>
<pre><code class="language-c">#define MASTER = 0; // assume we have 8 ranks
#define FROM_MASTER = 1;
#define FROM_WORKER = 2;
int main(int argc, char **argv)
{
    double NRA = atof(argv[1]);
    double NCA_NRB = atof(argv[2]);
    double NCB = atof(argv[3]);
    double A[NRA][NCA_NRB],
           B[NCA_NRB][NCB],
           C[NRA][NCB];
    int rankID,
        numOfRanks,
        averow,
        extra,
        offset
        mtype;

    offset = 0;
    MPI_Init(&amp;argc, &amp;argv);
    MPI_COMM_RANK(MPI_COMM_WORLD, &amp;rankID);
    MPI_COMM_SIZE(MPI_COMM_WORLD, &amp;numOfRanks);

    /*Master Operation*/
    if (rankID == MASTER)
    {
        averow = NRA/numOfRanks;
        extra  = NRA%numOfRanks;

        mtype = FROM_MASTER;

        ... code of generate matrix a and b...

        for(int dest = 1; dest &lt; numOfRanks; dest++)
        {
            int row = (dest &lt;= extra) ? averow + 1 : averow;
            printf(&quot;Sending %d row to rask %d\n&quot;, row, dest);
            MPI_Sent(&amp;offset, 1, MPI_INT, dest, mtype, MPI_COMM_WORLD);
            MPI_Sent(&amp;row, 1, MPI_INT, dest, mtype, MPI_COMM_WORLD);
            MPI_Sent(&amp;A[offset][0], row*NCA_NRB, MPI_DOUBLE, dest, mtype, MPI_COMM_WORLD);
            MPI_Sent(&amp;B, NCA_NRB*NCB, MPI_DOUBLE, dest, mtype, MPI_COMM_WORLD);
            offset += row;
        }

        mytype = FROM_WORKER;
        for (int dest = 1; dest &lt; numOfRanks; dest++)
        {
            printf(&quot;receive %d row to rask %d\n&quot;, row, dest);
            MPI_Recv(&amp;offset, 1, MPI_INT, dest, mtype, MPI_COMM_WORLD, &amp;status);
            MPI_Recv(&amp;row, 1, MPI_INT, dest, mtype, MPI_COMM_WORLD, &amp;status);
            MPI_Recv(&amp;C[offset][0], row*NCB, MPI_DOUBLE, dest, mtype， MPI_COMM_WORLD, &amp;status);
        }

        
    }

    if （rankID != MASTER）
    {
        mtype = FROM_MASTER;
        MPI_Recv(&amp;offset, 1, MPI_INT, MASTER, mtype, MPI_COMM_WORLD, &amp;status);
        MPI_Recv(&amp;row, 1, MPI_INT, MASTER, mtype, MPI_COMM_WORLD, &amp;status);
        MPI_Recv(&amp;A[offset][0], row*NCA_NRB, MPI_INT, MASTER, mtype, MPI_COMM_WORLD, &amp;status);
        MPI_Recv(&amp;B, NCB*NCA_NRB, MPI_INT, MASTER, mtype, MPI_COMM_WORLD, &amp;status);

        ... code of computing the matrix multiplication ...

        mtype = FROM_WORKER;
        MPI_Send(&amp;offset, 1, MPI_INT, MASTER, mtype, MPI_COMM_WORLD);
        MPI_Send(&amp;row, 1, MPI_INT, MASTER, mtype, MPI_COMM_WORLD);
        MPI_Send(&amp;C[offset][0], row*NCB, MPI_INT, MASTER, mtype, MPI_COMM_WORLD);
    }
}
</code></pre>
<h2 id="reference">Reference</h2>
<p>[1]:<a href="https://mpitutorial.com/tutorials/dynamic-receiving-with-mpi-probe-and-mpi-status/">MPI Tutorial</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[MMU(memory management unit)学习笔记V0.0.0]]></title>
        <id>https://DX990307.github.io/post/mmumemory-management-unitxue-xi-bi-ji-v000/</id>
        <link href="https://DX990307.github.io/post/mmumemory-management-unitxue-xi-bi-ji-v000/">
        </link>
        <updated>2023-03-02T08:29:34.000Z</updated>
        <content type="html"><![CDATA[<p>Previously, I wanted to learn the structure of the memory management unit in <em>computer architecture -- a quantitative approach</em> comperhensively. However, I cannot find a chapter that inturduce MMU in the book. In that case, I read some materials on the Internet and try to write something to record what I am learnt from the wikipedia and other documents.</p>
<h3 id="brief-introduction-about-memory-management-unitmmu">Brief introduction about memory management unit(MMU)</h3>
<p>MMU(memory management unit), also called PMMU (paged memory management unit). It is responsible for the translation of virtual addresses to physical addresses. MMUs also have some functions such as memory protection, cache control, bus arbitration etc.</p>
<p>In different computer architecture, the place of the MMU in the computer architecture are different. Sometimes engineers let the TLB as a part of the MMU. some times the TLB and the MMU are indivadual components in the computer architecture.</p>
<h3 id="prerequisite-knowledge">prerequisite knowledge</h3>
<p><strong>physical addresses and virtual addresses</strong><br>
The benefit of using virtual addresses is that it allows management software, such as an Operating System (OS), to control the view of memory that is presented to software. The OS can control what memory is visible, the virtual address at which that memory is visible, and what accesses are permitted to that memory. This allows the OS to sandbox applications (hiding the resources of one application from another application) and to provide abstraction from the underlying hardware.</p>
<p>One benefit of using virtual addresses is that an OS can present multiple fragmented physical regions of memory as a single, contiguous virtual address space to an application.</p>
<p>Virtual addresses also benefit software developers, who will not know a system’s exact memory addresses when writing their application. With virtual addresses, software developers do not need to concern themselves with the physical memory. The application knows that it is up to the OS and the hardware to work together to perform the address translation.</p>
<p>In practice, each application can use its own set of virtual addresses that will be mapped to different locations in the physical system. As the operating system switches between different applications it re-programs the map. This means that the virtual addresses for the current application will map to the correct physical location in memory.</p>
<p>Virtual addresses are translated to physical addresses through mappings.</p>
<p><strong>page table and page entry</strong><br>
In one word, the page table is a lookup table used by a virtual memory system in a computer operating system to store the mapping between virtual addresses and physical addresses.</p>
<p>The page entry is a structure that holds the mapping between a virtual page and corresponding physical frame, it also contains other information such as a dirty bit or a modified bit.</p>
<h3 id="the-memory-management-unitmmu">The memory management unit(MMU)</h3>
<p>The major component of the MMU is the table walk unit and a very large page table. The table walk unit processes the page table walk operation that find the physical address by the given virtual address the page table.</p>
<p>MMUs also has other control logic to modify the property of PTEs which is pretty significant since such property can guarantee the data is what the processor needs.</p>
<h3 id="implemented-by-simulator">Implemented by simulator</h3>
<p><a href="https://gitlab.com/akita/mem/-/tree/v3/vm/mmu">https://gitlab.com/akita/mem/-/tree/v3/vm/mmu</a><br>
<a href="https://pages.cs.wisc.edu/~swilson/gem5-docs/x86_2tlb_8cc_source.html">https://pages.cs.wisc.edu/~swilson/gem5-docs/x86_2tlb_8cc_source.html</a></p>
<h3 id="reference-useful-links">reference &amp; useful links</h3>
<p><a href="https://developer.arm.com/documentation/101811/0102/The-Memory-Management-Unit--MMU-">https://developer.arm.com/documentation/101811/0102/The-Memory-Management-Unit--MMU-</a><br>
<a href="https://en.wikipedia.org/wiki/Input%E2%80%93output_memory_management_unit">https://en.wikipedia.org/wiki/Input–output_memory_management_unit</a><br>
<a href="https://en.wikipedia.org/wiki/Memory_management_unit">https://en.wikipedia.org/wiki/Memory_management_unit</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Git Opeartions]]></title>
        <id>https://DX990307.github.io/post/git-opeartions/</id>
        <link href="https://DX990307.github.io/post/git-opeartions/">
        </link>
        <updated>2023-01-11T10:52:20.000Z</updated>
        <content type="html"><![CDATA[<ul>
<li>Useful Links<br>
<a href="https://backlog.com/git-tutorial/cn/">https://backlog.com/git-tutorial/cn/</a></li>
<li>Cover local files by files from servers<pre><code>git fetch --all
git reset --hard origin/xxx (the branch that wants to be covered)
git pull
</code></pre>
</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Useful links]]></title>
        <id>https://DX990307.github.io/post/useful-links/</id>
        <link href="https://DX990307.github.io/post/useful-links/">
        </link>
        <updated>2023-01-08T14:18:01.000Z</updated>
        <content type="html"><![CDATA[<ul>
<li>
<p>Git operation<br>
<a href="https://backlog.com/git-tutorial/cn/">https://backlog.com/git-tutorial/cn/</a></p>
</li>
<li>
<p>Pandas<br>
<a href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html">https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html</a></p>
</li>
<li>
<p>Seaborn<br>
<a href="https://seaborn.pydata.org/generated/seaborn.swarmplot.html">https://seaborn.pydata.org/generated/seaborn.swarmplot.html</a></p>
<h2 id="s">S</h2>
</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hello Gridea]]></title>
        <id>https://DX990307.github.io/post/hello-gridea/</id>
        <link href="https://DX990307.github.io/post/hello-gridea/">
        </link>
        <updated>2018-12-11T16:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p>👏  欢迎使用 <strong>Gridea</strong> ！<br>
✍️  <strong>Gridea</strong> 一个静态博客写作客户端。你可以用它来记录你的生活、心情、知识、笔记、创意... ...</p>
]]></summary>
        <content type="html"><![CDATA[<p>👏  欢迎使用 <strong>Gridea</strong> ！<br>
✍️  <strong>Gridea</strong> 一个静态博客写作客户端。你可以用它来记录你的生活、心情、知识、笔记、创意... ...</p>
<!-- more -->
<p><a href="https://github.com/getgridea/gridea">Github</a><br>
<a href="https://gridea.dev/">Gridea 主页</a><br>
<a href="https://fehey.com/">示例网站</a></p>
<h2 id="特性">特性👇</h2>
<p>📝  你可以使用最酷的 <strong>Markdown</strong> 语法，进行快速创作</p>
<p>🌉  你可以给文章配上精美的封面图和在文章任意位置插入图片</p>
<p>🏷️  你可以对文章进行标签分组</p>
<p>📋  你可以自定义菜单，甚至可以创建外部链接菜单</p>
<p>💻  你可以在 <strong>Windows</strong>，<strong>MacOS</strong> 或 <strong>Linux</strong> 设备上使用此客户端</p>
<p>🌎  你可以使用 <strong>𝖦𝗂𝗍𝗁𝗎𝖻 𝖯𝖺𝗀𝖾𝗌</strong> 或 <strong>Coding Pages</strong> 向世界展示，未来将支持更多平台</p>
<p>💬  你可以进行简单的配置，接入 <a href="https://github.com/gitalk/gitalk">Gitalk</a> 或 <a href="https://github.com/SukkaW/DisqusJS">DisqusJS</a> 评论系统</p>
<p>🇬🇧  你可以使用<strong>中文简体</strong>或<strong>英语</strong></p>
<p>🌁  你可以任意使用应用内默认主题或任意第三方主题，强大的主题自定义能力</p>
<p>🖥  你可以自定义源文件夹，利用 OneDrive、百度网盘、iCloud、Dropbox 等进行多设备同步</p>
<p>🌱 当然 <strong>Gridea</strong> 还很年轻，有很多不足，但请相信，它会不停向前 🏃</p>
<p>未来，它一定会成为你离不开的伙伴</p>
<p>尽情发挥你的才华吧！</p>
<p>😘 Enjoy~</p>
]]></content>
    </entry>
</feed>